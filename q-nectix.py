# -*- coding: utf-8 -*-
"""qtrader.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mvzfQQQTI_8ngfyV1ARzGQzDb12cvjiX
"""

# !pip install tensorflow-gpu==2.0.0.alpha0 tensorflow==2.0.0 pandas-datareader

# !pip install tensorflow==2.0.0

# !pip install pandas-datareader

import os
import sys
import time
import math
import random
import configparser
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
import pandas_datareader as data_reader
import alpaca_trade_api as tradeapi
from tqdm import tqdm_notebook, tqdm
from collections import deque
from datetime import date

# tf.__version__

# csv_file = 'drive/My Drive/Colab Notebooks/IPI_data_1575436411.0203404.csv'

weeks = 54*2
ticker = 'IPI'
config = configparser.ConfigParser()

try:
    config.read(os.path.relpath('drive/My Drive/Colab Notebooks/config.ini'))
except FileExistsError as e:
    print('FileExistsError: {}'.format(e))
    sys.exit(1)

def time_formatter(time_stamp, time_format=None):
    """Return a formatted date in open market hours given a timestamp.
    :param time_stamp:
    :param time_format:
    :return:
    """
    if not time_stamp or time_stamp is None or type(time_stamp) is not float:
        raise ValueError
    if time_format is None:
        time_format = '%Y-%m-%dT09:30:00-04:00'
    return date.fromtimestamp(time_stamp).strftime(time_format)

def set_candlestick_df(bars):
    """Given a collection of candlestick bars, return a dataframe.
    Dataframe should contain keys:
        - time, open, high, low, close, volume
    :param bars:
    :return:
    """
    if not bars or bars is None:
        raise ValueError('Bars cannot be none')

    idx = [bar.t for bar in bars if bar is not None]

    data            = pd.DataFrame(index=idx)
    data['open']    = [bar.o for bar in bars if bar is not None]
    data['high']    = [bar.h for bar in bars if bar is not None]
    data['low']     = [bar.l for bar in bars if bar is not None]
    data['close']   = [bar.c for bar in bars if bar is not None]
    data['volume']  = [bar.v for bar in bars if bar is not None]

    return data

def get_bars(ticker, backdate, config):
  """Get bars from Alpaca API."""
  alpaca_api = tradeapi.REST(
      base_url    = config['alpaca']['APCA_API_BASE_URL'],
      key_id      = config['alpaca']['APCA_API_KEY_ID'],
      secret_key  = config['alpaca']['APCA_API_SECRET_KEY'],
      api_version = config['alpaca']['VERSION']
  )
  trading_account = alpaca_api.get_account()

  return alpaca_api.get_barset(ticker, '1D', after=backdate)

# bars = get_bars(ticker, weeks, config)[ticker]
# data = set_candlestick_df(bars)


def sigmoid(num):
    """Return the sigmoid value of num.

    :return: sigmoid value
    """
    return 1 / (1 + math.exp(-num))

def price_format(num):
    """Print the price with proper decimal, positive and negative formatting.

    :return: formatted stock price
    """
    if num < 0:
        return '- ${0:2f}'.format(abs(num))
    else:
        return '${0:2f}'.format(abs(num))

def load_dataset(ticker, start_date):
    """Load the dataset for a given ticker symbol.

    :param ticker: a stock ticker symbol
    :param start_date: a stock ticker symbol
    :return close: return the most recent closing price in the time series
    """

    dataset = data_reader.DataReader(ticker, data_source='yahoo')
    start_date = str(dataset.index[0]).split()[0]
    end_date = str(dataset.index[-1]).split()[0]
    close = dataset['Close']
    return close

def create_state(data, step, window_size):
    """Create state (duh).

    :param data:
    :param step:
    :param window_size:
    :return :
    """
    starting_id = step - window_size + 1

    if starting_id >= 0:
        windowed_data = data[starting_id:step+1]
    else:
        windowed_data =  -starting_id * [data[0]] + list(data[0:step+1])

    state = []
    for i in range(window_size - 1):
        state.append(sigmoid(windowed_data[i+1] - windowed_data[i]))
    return np.array([state])

class Qtrader():

    def __init__(self, state_size, action_space=3, model_name='Qtrader'):
        """Initialize the AI trader class.

        :param state_size:
        :param action_space: stay in position, buy, sell
        :param model_name:
        """
        self.state_size = state_size
        self.action_space = action_space
        self.memory = deque(maxlen=2000)
        self.inventory = []
        self.model_name = model_name

        # maximize current reward over long term rewards
        self.gamma = 0.95

        # should we use a random action or let the model choose?
        # in beginning, this will be random and will taper off as the system learns
        self.epsilon = 1.0

        # when epison == this, stop decresing
        self.epsilon_final = 0.01

        # how fast should the epsilon decrease?
        self.epsilon_decay = 0.995

        # initialize the model
        self.model = self.model_builder()

    def model_builder(self):
        """Build our model."""

        model = tf.keras.models.Sequential()

        # first dense layer
        model.add(tf.keras.layers.Dense(units=32, activation='relu', input_dim=self.state_size))

        # second layer
        model.add(tf.keras.layers.Dense(units=64, activation='relu'))

        # third layer
        model.add(tf.keras.layers.Dense(units=128, activation='relu'))

        # output layer
        model.add(tf.keras.layers.Dense(units=self.action_space, activation='linear'))

        # compile the model
        model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(lr=0.001))

        return model

    def trade(self, state):
        """Determine if action should be random or from the model and trade.

        :param state:
        :return:
        """
        # if the random number is less than the epsilon value, act randomly
        if random.random() <= self.epsilon:
            return random.randrange(self.action_space)

        # make a prediction given a state argument
        actions = self.model.predict(state)
        return np.argmax(actions[0])

    def batch_trade(self, batch_size):
        """Loop through and execute all trades in a batch.

        :param batch_size: the number of trades to make
        """
        batch = []

        # iterate through deque memory
        for i in range(len(self.memory) - batch_size + 1, len(self.memory)):
            # append value from the end
            batch.append(self.memory[i])

        # train the model
        for state, action, reward, next_state, done in batch:
            # state, action, reward, next_state, done
            reward = reward

            # terminal (done) state?
            if not done:
                # calculate reward
                reward = reward + self.gamma * np.amax(self.model.predict(next_state)[0])

            # set a target variable
            target = self.model.predict(state)

            target[0][action] = reward

            # fit the model now that we have target and state
            self.model.fit(state,target,epochs=1,verbose=0)

        # decrease epsilon by epsilon_decay value
        if self.epsilon > self.epsilon_final:
            self.epsilon *= self.epsilon_decay


backdate = time_formatter(time.time() - (604800 * weeks), '%Y-%m-%d')
data = load_dataset(ticker, backdate)   # .iloc[-100:]
# data = pd.read_csv(csv_file)
# for key in data.keys():
#   if key != 'close':
#     print('Popping key:', key)
#     data.pop(key)
data.head(50)

# Some hyperparameters to play with
window_size = 10
episodes = 1000
batch_size = 32
data_samples = len(data) - 1

trader = Qtrader(window_size)

trader.model.summary()


def run():
    # do the thang
    for episode in range(episodes + 1):
        print('Episode\t {}/{}'.format(episode, episodes))
        state = create_state(data, 0, window_size+1)
        total_profit = 0
        trader.inventory = []
        for t in tqdm(range(data_samples)):
            action = trader.trade(state)
            next_state = create_state(data, t+1, window_size+1)
            reward = 0

            if action == 1:     # buy
                trader.inventory.append(data[t])

            elif action == 2 and len(trader.inventory) > 0:   # sell
                buy_price = trader.inventory.pop(0)
                reward = max(data[t] - buy_price, 0)
                total_profit += data[t] - buy_price

            if t == data_samples - 1:
                done = True
            else:
                done = False

            trader.memory.append([state, action, reward, next_state, done])
            state = next_state

            if done:
                print('Total profit:\t'.ljust(10), str(total_profit))

            if len(trader.memory) > batch_size:
                trader.batch_trade(batch_size)
        if episode %10 == 0:
            trader.model.save('Qtrader_{}.h5'.format(episode))


run()
