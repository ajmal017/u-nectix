{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from empyrical import max_drawdown, alpha, beta\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from src.twitter_interface import TwitterInterface\n",
    "from src.asset_selector import AssetSelector\n",
    "from src.indicators import Indicators\n",
    "from util import time_formatter\n",
    "from src.predictor import Predictor\n",
    "from sklearn.cluster import KMeans\n",
    "import alpaca_trade_api as tradeapi\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser\n",
    "import requests\n",
    "import twitter\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "weeks = 13\n",
    "\n",
    "backdate = time_formatter(time.time() - (604800 * weeks))\n",
    "config = configparser.ConfigParser()\n",
    "try:\n",
    "    config.read(os.path.relpath(\"config.ini\"))\n",
    "except FileExistsError as e:\n",
    "    print(\"FileExistsError: {}\".format(e))\n",
    "    sys.exit(1)\n",
    "alpaca_api = tradeapi.REST(\n",
    "    base_url    = config[\"alpaca\"][\"APCA_API_BASE_URL\"],\n",
    "    key_id      = config[\"alpaca\"][\"APCA_API_KEY_ID\"],\n",
    "    secret_key  = config[\"alpaca\"][\"APCA_API_SECRET_KEY\"],\n",
    "    api_version = config[\"alpaca\"][\"VERSION\"]\n",
    ")\n",
    "twitter_api = twitter.Api(\n",
    "    config[\"twitter\"][\"CONSUMER_KEY\"],\n",
    "    config[\"twitter\"][\"CONSUMER_SECRET\"],\n",
    "    config[\"twitter\"][\"ACCESS_TOKEN_KEY\"],\n",
    "    config[\"twitter\"][\"ACCESS_TOKEN_SECRET\"]\n",
    ")\n",
    "tq_key = config[\"tenquant\"][\"api_key\"]\n",
    "\n",
    "tdf = pd.DataFrame()\n",
    "ti = TwitterInterface(twitter_api, tdf)\n",
    "trading_account = alpaca_api.get_account()\n",
    "\n",
    "selector = AssetSelector(alpaca_api, edgar_token=None)\n",
    "\n",
    "def get_sentiment(text):\n",
    "    \"\"\"Given a text block, return a sentiment score based.\n",
    "    :param text:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    text_polarity   = sid.polarity_scores(text)\n",
    "\n",
    "    if text_polarity[\"compound\"] > 0.50:\n",
    "        sentiment   = \"positive\"\n",
    "    else:\n",
    "        sentiment   = \"negative\"\n",
    "    return sentiment, text_polarity[\"compound\"]\n",
    "\n",
    "def get_losers():\n",
    "    print('Losers'.center(45))\n",
    "    print()\n",
    "    print('Ticker'.ljust(10), 'Last'.ljust(11), 'Change'.ljust(11), 'Pct Loss')\n",
    "    print(\"{:<30}\".format('–' * 45))\n",
    "    for symbol in range(len(alpaca_api.polygon.gainers_losers(\"losers\"))):\n",
    "        \n",
    "        # print out some indicators here # TODO\n",
    "        # also throw out shitty stocks\n",
    "        \n",
    "        print(alpaca_api.polygon.gainers_losers(\"losers\")[symbol].ticker.ljust(10),\n",
    "              '$' + str(alpaca_api.polygon.gainers_losers(\"losers\")[symbol].lastTrade['p']).ljust(10),\n",
    "              '$' + str(alpaca_api.polygon.gainers_losers(\"losers\")[symbol].todaysChange).ljust(10),\n",
    "              str(alpaca_api.polygon.gainers_losers(\"losers\")[symbol].todaysChangePerc)+'%')\n",
    "\n",
    "def get_gainers():\n",
    "    print('Gainers'.center(45))\n",
    "    print()\n",
    "    print('Ticker'.ljust(10), 'Last'.ljust(11), 'Change'.ljust(11), 'Pct Gain')\n",
    "    print(\"{:<30}\".format('–' * 45))\n",
    "    for symbol in range(len(alpaca_api.polygon.gainers_losers())):\n",
    "        \n",
    "        # print out some indicators here # TODO\n",
    "        # also throw out shitty stocks\n",
    "        \n",
    "        print(alpaca_api.polygon.gainers_losers()[symbol].ticker.ljust(10),\n",
    "              '$' + str(alpaca_api.polygon.gainers_losers()[symbol].lastTrade['p']).ljust(10),\n",
    "              '$' + str(alpaca_api.polygon.gainers_losers()[symbol].todaysChange).ljust(10),\n",
    "              str(alpaca_api.polygon.gainers_losers()[symbol].todaysChangePerc)+'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    get_gainers()\n",
    "    print()\n",
    "    get_losers()\n",
    "    print()\n",
    "    print(\"Bulls\".center(45))\n",
    "    bulls = selector.bullish_candlesticks(64, 20)\n",
    "    print()\n",
    "    print(\"Bears\".center(45))\n",
    "    bears = selector.bearish_candlesticks(64, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"OSS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "stocktwits = requests.post(\"https://api.stocktwits.com/api/2/streams/symbol/{}.json\".format(ticker))\n",
    "stocktwits = json.loads(stocktwits.text)\n",
    "stocktwitstext = \"\\n\".join([m[\"body\"] for m in stocktwits[\"messages\"]])\n",
    "tweets = ti.get_tweets(ticker, \"stock\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stsentiment, stscore = get_sentiment(stocktwitstext)\n",
    "tsentiment, tscore = get_sentiment(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Sentiment score for {}\".format(ticker))\n",
    "print(\"{:<30}\".format('–' * 45))\n",
    "print(\"Stocktwits:\\t{}\\t score: {}\\nTwitter:\\t{}\\t score:\\t{}\".format(stsentiment, stscore, tsentiment, tscore))\n",
    "print(\"Average:\\t{}\".format((stscore + tscore)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# alpaca_api.polygon.historic_trades(ticker, '2019-10-10', limit=10)\n",
    "# alpaca_api.polygon.news(ticker)\n",
    "# alpaca_api.polygon.last_trade(ticker)\n",
    "# alpaca_api.polygon.last_quote(ticker)\n",
    "# alpaca_api.polygon.company(ticker)\n",
    "# alpaca_api.polygon.dividends(ticker)\n",
    "# alpaca_api.polygon.financials(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenquant_data = requests.get(\"https://api.tenquant.io/data?key={}&ticker={}\".format(tq_key, ticker))\n",
    "tenquant_data = json.loads(tenquant_data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stocktwits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tenquant_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
